{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rodri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rodri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\rodri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Baixar recursos do NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Definindo as nossas stopwords\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "# Carregar o modelo de lematização\n",
    "import spacy\n",
    "lemmatizer = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar datasets\n",
    "df_train = pd.read_parquet(R'C:\\Users\\rodri\\Desktop\\datathon-fiap-final\\train\\train-all-parts.parquet', engine='pyarrow')\n",
    "df_items = pd.read_parquet(R'C:\\Users\\rodri\\Desktop\\datathon-fiap-final\\itens\\itens-all-parts.parquet', engine='pyarrow')\n",
    "df_validation = pd.read_parquet(R'C:\\Users\\rodri\\Desktop\\datathon-fiap-final\\validation.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipagem das colunas para otimização de memória\n",
    "df_train = df_train.astype({\n",
    "    'userId': 'string',\n",
    "    'userType': 'category',\n",
    "    'historySize': 'uint8',\n",
    "    'history': 'string',\n",
    "    'timestampHistory': 'string',\n",
    "    'numberOfClicksHistory': 'string',\n",
    "    'timeOnPageHistory': 'string',\n",
    "    'scrollPercentageHistory': 'string',\n",
    "    'pageVisitsCountHistory': 'string',\n",
    "})\n",
    "\n",
    "df_items = df_items.astype({\n",
    "    'page': 'string',\n",
    "    'url': 'string',\n",
    "    'issued': 'string',\n",
    "    'modified': 'string',\n",
    "    'title': 'string',\n",
    "    'body': 'string',\n",
    "    'caption': 'string'\n",
    "})\n",
    "\n",
    "df_validation = df_validation.astype({\n",
    "    'userId': 'string',\n",
    "    'userType': 'category',\n",
    "    'history': 'string',\n",
    "    'timestampHistory': 'string'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3 style='color:yellow; font-weight:bold; margin:0;'>Informações do DataFrame de Treino</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p style='margin:0; padding-left:20px;'>Shape: (577942, 10)</br>Uso de memória: 966.8433818817139 MB</br>Columns: ['userId', 'userType', 'historySize', 'history', 'timestampHistory', 'numberOfClicksHistory', 'timeOnPageHistory', 'scrollPercentageHistory', 'pageVisitsCountHistory', 'timestampHistory_new']</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='color:yellow; font-weight:bold; margin:0;'>Informações do DataFrame de Itens</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p style='margin:0; padding-left:20px;'>Shape: (255603, 7)</br>Uso de memória: 1413.6674976348877 MB</br>Columns: ['page', 'url', 'issued', 'modified', 'title', 'body', 'caption']</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='color:yellow; font-weight:bold; margin:0;'>Informações do DataFrame de Validação</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p style='margin:0; padding-left:20px;'>Shape: (112184, 4)</br>Uso de memória: 35.148698806762695 MB</br>Columns: ['userId', 'userType', 'history', 'timestampHistory']</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_dataframe_info(df: pd.DataFrame, title: str) -> None:\n",
    "    display(HTML(f\"<h3 style='color:yellow; font-weight:bold; margin:0;'>{title}</h3>\"))\n",
    "    display(HTML(f\"<p style='margin:0; padding-left:20px;'>Shape: {df.shape}</br>Uso de memória: {df.memory_usage(deep=True).sum() / (1024**2)} MB</br>Columns: {list(df.columns)}</p>\"))\n",
    "\n",
    "display_dataframe_info(df_train, \"Informações do DataFrame de Treino\")\n",
    "display_dataframe_info(df_items, \"Informações do DataFrame de Itens\")\n",
    "display_dataframe_info(df_validation, \"Informações do DataFrame de Validação\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter colunas em listas\n",
    "def convert_to_list(df: pd.DataFrame, column_name: str, dtype: str = str) -> pd.Series:\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in DataFrame\")\n",
    "    \n",
    "    def safe_convert(value):\n",
    "        if isinstance(value, str):\n",
    "            return list(map(dtype, value.split(', ')))\n",
    "        elif pd.isna(value):\n",
    "            return []\n",
    "        else:\n",
    "            return [dtype(value)]\n",
    "    \n",
    "    return df[column_name].apply(safe_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar conversão para listas\n",
    "df_train['history'] = convert_to_list(df_train, 'history', dtype=str)\n",
    "df_train['timestampHistory'] = convert_to_list(df_train, 'timestampHistory', dtype=np.int64)\n",
    "df_train['numberOfClicksHistory'] = convert_to_list(df_train, 'numberOfClicksHistory', dtype=np.uint16)\n",
    "df_train['timeOnPageHistory'] = convert_to_list(df_train, 'timeOnPageHistory', dtype=np.int32)\n",
    "df_train['scrollPercentageHistory'] = convert_to_list(df_train, 'scrollPercentageHistory', dtype=np.float32)\n",
    "df_train['pageVisitsCountHistory'] = convert_to_list(df_train, 'pageVisitsCountHistory', dtype=np.uint16)\n",
    "\n",
    "# Criar novas features\n",
    "df_train['avg_time_on_page'] = df_train['timeOnPageHistory'].apply(lambda x: np.mean(x) if x else 0)\n",
    "df_train['total_clicks'] = df_train['numberOfClicksHistory'].apply(np.sum)\n",
    "df_train['avg_scroll_percentage'] = df_train['scrollPercentageHistory'].apply(lambda x: np.mean(x) if x else 0)\n",
    "\n",
    "df_train['timestampHistory'] = df_train['timestampHistory'].apply(lambda x: pd.to_datetime(x, errors='coerce'))\n",
    "df_train['recency_days'] = (pd.Timestamp.now() - df_train['timestampHistory'].apply(max)).dt.days\n",
    "\n",
    "df_train = df_train.dropna(subset=['recency_days']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text: str) -> str:\n",
    "    # Converte o texto para minúsculo\n",
    "    text = text.lower()\n",
    "\n",
    "    # Processa o texto com SpaCy (tokenização + POS tagging + etc.)\n",
    "    doc = lemmatizer(text)\n",
    "\n",
    "    processed_tokens = []\n",
    "    for token in doc:\n",
    "        # Checa se não é pontuação, não é espaço, não é stopword \n",
    "        # (você pode usar tanto a lista 'stop_words' quanto token.is_stop)\n",
    "        if not token.is_punct and not token.is_space and token.text not in stop_words:\n",
    "            # Usa a forma lematizada do token\n",
    "            processed_tokens.append(token.lemma_)\n",
    "\n",
    "    # Junta os tokens lematizados em uma string novamente\n",
    "    return ' '.join(processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute esse código caso o treinamento esteja muito lento.\n",
    "\n",
    "# def remove_stopwords(text: str) -> str:\n",
    "#     words = word_tokenize(str(text).lower())\n",
    "#     words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "#     return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_copy = df_items.copy()\n",
    "\n",
    "# Processamento dos itens\n",
    "df_items['issued'] = pd.to_datetime(df_items['issued'], errors='coerce')\n",
    "df_items['modified'] = pd.to_datetime(df_items['modified'], errors='coerce')\n",
    "df_items['recency_days'] = (pd.to_datetime(df_items['modified']).max() - df_items['modified']).dt.days\n",
    "\n",
    "\n",
    "df_items['title_clean'] = df_items['title'].apply(remove_stopwords)\n",
    "df_items['body_clean'] = df_items['body'].apply(remove_stopwords)\n",
    "df_items['content_clean'] = (df_items['title_clean'] + ' ' + df_items['body_clean']).str.strip()\n",
    "df_items = df_items.drop_duplicates(subset=['page']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explodir histórico de leitura\n",
    "df_user_news = df_train.explode('history')\n",
    "df_user_news.rename(columns={'history': 'page'}, inplace=True)\n",
    "\n",
    "# União do dataframe de treino com items\n",
    "df_train_final = df_user_news.merge(df_items, on='page', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar vetores TF-IDF para o conteúdo das notícias\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=list(stop_words),\n",
    "    max_features=2000,\n",
    "    max_df=0.95,\n",
    "    min_df=0.05,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "tfidf_matrix = vectorizer.fit_transform(df_items['content_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a similaridade em lotes para evitar estouro de memória\n",
    "def batch_cosine_similarity(matrix, batch_size=1000):\n",
    "    n = matrix.shape[0]\n",
    "    similarity_dict = {}\n",
    "\n",
    "    for start in range(0, n, batch_size):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch_sim = cosine_similarity(matrix[start:end], matrix)\n",
    "\n",
    "        for i, idx in enumerate(range(start, end)):\n",
    "            similar_indices = batch_sim[i].argsort()[-6:-1][::-1]  # Pegamos as 5 mais similares (excluindo ela mesma)\n",
    "            similarity_dict[df_items.iloc[idx]['page']] = df_items.iloc[similar_indices]['page'].tolist()\n",
    "\n",
    "    return similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_noticias = batch_cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_user_news já possui colunas: ['userId', 'page', 'timestampHistory', 'total_clicks', ...]\n",
    "# Precisamos sumarizar ou criar algum score de popularidade por notícia\n",
    "\n",
    "popularity = (\n",
    "    df_user_news\n",
    "    .groupby('page', as_index=False)\n",
    "    .agg({\n",
    "        'total_clicks': 'sum',\n",
    "        'avg_scroll_percentage': 'mean',\n",
    "    })\n",
    ")\n",
    "\n",
    "# Exemplo de score de popularidade\n",
    "popularity['popularity_score'] = (\n",
    "    popularity['total_clicks'] * 0.3 +\n",
    "    popularity['avg_scroll_percentage'] * 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_items.merge(popularity[['page', 'popularity_score']], on='page', how='left')\n",
    "df_items['popularity_score'] = df_items['popularity_score'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_noticias(\n",
    "        user_id: str, df_train_final: pd.DataFrame, df_items: pd.DataFrame, similar_noticias: dict, top_n: int = 5) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Função para recomendar notícias personalizadas para um usuário.\n",
    "    \n",
    "#     Se o usuário tiver histórico suficiente, usa um modelo treinado para prever quais notícias ele consumirá.\n",
    "#     Se for um usuário novo ou anônimo (cold-start), recomenda notícias populares recentes.\n",
    "    \n",
    "#     Args:\n",
    "#         user_id (str): ID do usuário.\n",
    "#         df_train_final (DataFrame): Dados de interação dos usuários após processo dos de pré-processamento.\n",
    "#         df_items (DataFrame): Dados das notícias.\n",
    "#         top_n (int): Número de recomendações a retornar.\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: Notícias recomendadas com score ordenado.\n",
    "#     \"\"\"\n",
    "\n",
    "    # Garantir que 'popularity_score' e 'recency_days' existem\n",
    "    if 'popularity_score' not in df_items.columns:\n",
    "        print(\"⚠️ Atenção: 'popularity_score' não encontrado! Substituindo por 0.\")\n",
    "        df_items['popularity_score'] = 0\n",
    "\n",
    "    if 'recency_days' not in df_items.columns:\n",
    "        print(\"⚠️ Atenção: 'recency_days' não encontrado! Substituindo por 0.\")\n",
    "        df_items['recency_days'] = 0\n",
    "\n",
    "    # 🔹 Verificar se o usuário já tem histórico de leitura\n",
    "    user_history_df = df_train_final[df_train_final['userId'] == user_id]\n",
    "\n",
    "    if user_history_df.empty:\n",
    "        # 🚀 Cold-Start: Recomendar notícias populares\n",
    "        print(f\"⚠️ Usuário {user_id} sem histórico, usando recomendação por popularidade.\")\n",
    "\n",
    "        df_items['engagement_score'] = (\n",
    "            df_items['popularity_score'] * 0.8 +\n",
    "            df_items['recency_days'].apply(lambda x: -0.2 * x if pd.notna(x) else 0)\n",
    "        )\n",
    "        return df_items.sort_values('engagement_score', ascending=False).head(top_n)\n",
    "\n",
    "    else:\n",
    "        # 🚀 Usuário com histórico: Recomendação baseada no modelo\n",
    "        print(f\"✅ Usuário {user_id} encontrado! Usando modelo de Machine Learning.\")\n",
    "        noticias_lidas = user_history_df['page'].unique().tolist()\n",
    "\n",
    "        noticias_similares = []\n",
    "        for noticia in noticias_lidas:\n",
    "            if noticia in similar_noticias:\n",
    "                noticias_similares.extend(similar_noticias[noticia])\n",
    "\n",
    "        # Verificar se encontramos notícias similares\n",
    "        if not noticias_similares:\n",
    "            print(\"⚠️ Nenhuma notícia similar encontrada! Retornando notícias populares.\")\n",
    "            return df_items.sort_values('popularity_score', ascending=False).head(top_n)\n",
    "\n",
    "        df_candidate_news = df_items[df_items['page'].isin(noticias_similares) & ~df_items['page'].isin(noticias_lidas)]\n",
    "\n",
    "        if df_candidate_news.empty:\n",
    "            print(\"⚠️ Nenhuma notícia disponível para recomendação. Retornando populares.\")\n",
    "            return df_items.sort_values('popularity_score', ascending=False).head(top_n)\n",
    "\n",
    "        df_candidate_news['candidate_score'] = (\n",
    "            df_candidate_news['popularity_score'] * 0.5 +\n",
    "            df_candidate_news['recency_days'].apply(lambda x: -0.2 * x if pd.notna(x) else 0)\n",
    "        )\n",
    "\n",
    "        return df_candidate_news.sort_values('candidate_score', ascending=False).head(top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisamos do df_train_final ou df_user_news contendo userId + page\n",
    "df_train_final = df_user_news.merge(df_items, on='page', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Exibe todas as colunas sem truncamento\n",
    "pd.set_option('display.max_colwidth', None)  # Exibe todo o conteúdo das células"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_11476\\2824676940.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_candidate_news['candidate_score'] = (\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de chamada\n",
    "recomendacoes = recomendar_noticias('54462d26984ee3cb49263b3e77c4abe4d4e13023dbbf2d683e2e5c9e114004c1', df_train_final, df_items, similar_noticias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>recency_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60121</th>\n",
       "      <td>1f32787b-de2b-49be-8c20-ddaeae34cc22</td>\n",
       "      <td>Filha é presa por golpe estimado em R$ 725 milhões contra a mãe; quadros renomados roubados foram recuperados</td>\n",
       "      <td>http://g1.globo.com/rj/rio-de-janeiro/noticia/2022/08/10/policia-tenta-prender-pessoas-que-extorquiram-milhoes-de-idosa-no-rio.ghtml</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126452</th>\n",
       "      <td>5af379e6-1bd1-4cf8-a23c-03266fb77b2c</td>\n",
       "      <td>Casa abandonada em Higienópolis: Entenda o caso da mulher que vive em mansão de SP</td>\n",
       "      <td>http://g1.globo.com/sp/sao-paulo/noticia/2022/07/20/casa-abandonada-em-higienopolis-entenda-o-caso-da-mulher-que-vive-em-mansao-de-sp.ghtml</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52787</th>\n",
       "      <td>7c076eda-5b41-4b0f-815f-0f6400148b0c</td>\n",
       "      <td>Câmera registra momento em que apoiador de Bolsonaro invade festa e mata guarda municipal que era tesoureiro do PT, em Foz do Iguaçu</td>\n",
       "      <td>http://g1.globo.com/pr/oeste-sudoeste/noticia/2022/07/10/camera-registra-momento-em-que-atirador-invade-festa-e-mata-guarda-municipal-que-era-tesoureiro-do-pt-em-foz-do-iguacu.ghtml</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>ecc37a22-b730-4e3a-bc87-c3ba3403acbc</td>\n",
       "      <td>PM suspeito de atirar e matar campeão mundial de jiu-jítsu é preso após decisão da Justiça</td>\n",
       "      <td>http://g1.globo.com/sp/sao-paulo/noticia/2022/08/07/justica-determina-prisao-de-pm-suspeito-de-atirar-em-campeao-mundial-de-jiu-jitsu.ghtml</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120168</th>\n",
       "      <td>8d477e04-3bab-4ad9-8fe3-799059238a9c</td>\n",
       "      <td>Quem é Giovanni Quintella, anestesista preso em flagrante por estuprar grávida no parto; ele atuou em pelo menos 10 hospitais</td>\n",
       "      <td>http://g1.globo.com/rj/rio-de-janeiro/noticia/2022/07/11/quem-e-giovanni-quintella-anestesista-preso-em-flagrante-por-estuprar-gravida-durante-o-parto-ele-atuou-em-pelo-menos-10-hospitais.ghtml</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        page  \\\n",
       "60121   1f32787b-de2b-49be-8c20-ddaeae34cc22   \n",
       "126452  5af379e6-1bd1-4cf8-a23c-03266fb77b2c   \n",
       "52787   7c076eda-5b41-4b0f-815f-0f6400148b0c   \n",
       "4191    ecc37a22-b730-4e3a-bc87-c3ba3403acbc   \n",
       "120168  8d477e04-3bab-4ad9-8fe3-799059238a9c   \n",
       "\n",
       "                                                                                                                                       title  \\\n",
       "60121                          Filha é presa por golpe estimado em R$ 725 milhões contra a mãe; quadros renomados roubados foram recuperados   \n",
       "126452                                                    Casa abandonada em Higienópolis: Entenda o caso da mulher que vive em mansão de SP   \n",
       "52787   Câmera registra momento em que apoiador de Bolsonaro invade festa e mata guarda municipal que era tesoureiro do PT, em Foz do Iguaçu   \n",
       "4191                                              PM suspeito de atirar e matar campeão mundial de jiu-jítsu é preso após decisão da Justiça   \n",
       "120168         Quem é Giovanni Quintella, anestesista preso em flagrante por estuprar grávida no parto; ele atuou em pelo menos 10 hospitais   \n",
       "\n",
       "                                                                                                                                                                                                      url  \\\n",
       "60121                                                                http://g1.globo.com/rj/rio-de-janeiro/noticia/2022/08/10/policia-tenta-prender-pessoas-que-extorquiram-milhoes-de-idosa-no-rio.ghtml   \n",
       "126452                                                        http://g1.globo.com/sp/sao-paulo/noticia/2022/07/20/casa-abandonada-em-higienopolis-entenda-o-caso-da-mulher-que-vive-em-mansao-de-sp.ghtml   \n",
       "52787               http://g1.globo.com/pr/oeste-sudoeste/noticia/2022/07/10/camera-registra-momento-em-que-atirador-invade-festa-e-mata-guarda-municipal-que-era-tesoureiro-do-pt-em-foz-do-iguacu.ghtml   \n",
       "4191                                                          http://g1.globo.com/sp/sao-paulo/noticia/2022/08/07/justica-determina-prisao-de-pm-suspeito-de-atirar-em-campeao-mundial-de-jiu-jitsu.ghtml   \n",
       "120168  http://g1.globo.com/rj/rio-de-janeiro/noticia/2022/07/11/quem-e-giovanni-quintella-anestesista-preso-em-flagrante-por-estuprar-gravida-durante-o-parto-ele-atuou-em-pelo-menos-10-hospitais.ghtml   \n",
       "\n",
       "        recency_days  \n",
       "60121            323  \n",
       "126452           343  \n",
       "52787            354  \n",
       "4191             325  \n",
       "120168           350  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(recomendacoes[['page', 'title', 'url', 'recency_days']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo salvo com sucesso em ./modelo_recomendacao.pkl!\n"
     ]
    }
   ],
   "source": [
    "# Caminho para salvar\n",
    "pickle_path = \"./modelo_recomendacao.pkl\"\n",
    "\n",
    "# Criando um dicionário com os três objetos essenciais\n",
    "modelo_recomendacao = {\n",
    "    \"df_train_final\": df_train_final,\n",
    "    \"df_items\": df_items,\n",
    "    \"similar_noticias\": similar_noticias\n",
    "}\n",
    "\n",
    "# Salvando o modelo\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(modelo_recomendacao, f)\n",
    "\n",
    "print(f\"✅ Modelo salvo com sucesso em {pickle_path}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviroments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
